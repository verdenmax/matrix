# 作业二

## 题目一

求出BM25 得分。

先计算查询权重，由于cat在查询中出现了2次，则 $\frac{qtf}{k_3 + qtf} = \frac{2}{8 + 2} = 0.2$

计算TF 权重，cat 在d中出现2次，所以 tf = 2，则 $\frac{k_1 tf}{tf + k_1 (1 - b + b \frac{v_l}{v_{avg}})} = \frac{1.2 * 2}{2 + 1.2 *(1 - 0.6 + 0.6 * \frac{300}{200})} = \frac{2.4}{2 + 1.2 * 1.3}$

计算IDF权重，cat 在100篇文档中出现，df = 100。$log_2 \frac{N-df + 0.5}{df + 0.5} = log_2 \frac{1600.5}{100.5}$

则 

$$
w(cat, d) = \frac{qtf}{k_3 + qtf} \frac{k_1 tf}{tf + k_1 (1 - b + b \frac{v_l}{v_{avg}})} log_2 \frac{N-df + 0.5}{df + 0.5} 
\\= 0.2 \times \frac{2.4}{2 + 1.2 * 1.3} \times log_2 \frac{3201}{201} \approx 0.1348314 \times 3.99325527036 \approx 0.54
$$

## 题目二

(1)
Skip-grams (SG)
根据给定目标词预测上下文（位置独立）
适合处理大量上下文单词，能够更好地捕获上下文信息。

Continuous Bag of Words (CBOW)
根据（基于词袋模型的）上下文预测目标词
更擅长捕捉单词的稀疏特征。

(2)

cos(apple,desk) = $\frac{2}{3}$
cos(book,desk) = $\frac{5}{6}$
cos(car,desk) = $\frac{2}{3}$
cos(pencil,desk) = $\frac{5}{6}$

与desk最接近的词为 book 和 pencil。

## 题目三

根据题意可以写

$$
\begin{pmatrix}
A \\ B \\ C \\ D \\
\end{pmatrix}
=
\begin{pmatrix}
\frac{1}{4} \\ 
\frac{1}{4} \\ 
\frac{1}{4} \\ 
\frac{1}{4} 
\end{pmatrix}
$$

$$
\begin{pmatrix}\frac{3}{8}\\ \frac{5}{24}\\ \frac{5}{24}\\ \frac{5}{24}\end{pmatrix}
=
\begin{pmatrix}
0 & \frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & \frac{1}{2} & 0 & 0 
\end{pmatrix}
\begin{pmatrix}
\frac{1}{4} \\ 
\frac{1}{4} \\ 
\frac{1}{4} \\ 
\frac{1}{4} 
\end{pmatrix}
$$

$$
\begin{pmatrix}\frac{5}{16}\\ \frac{11}{48}\\ \frac{11}{48}\\ \frac{11}{48}\end{pmatrix}
=
\begin{pmatrix}
0 & \frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & \frac{1}{2} & 0 & 0 
\end{pmatrix}
\begin{pmatrix}\frac{3}{8}\\ \frac{5}{24}\\ \frac{5}{24}\\ \frac{5}{24}\end{pmatrix}
$$

$$
\begin{pmatrix}\frac{11}{32}\\ \frac{7}{32}\\ \frac{7}{32}\\ \frac{7}{32}\end{pmatrix}
=
\begin{pmatrix}
0 & \frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & \frac{1}{2} & 0 & 0 
\end{pmatrix}
\begin{pmatrix}\frac{5}{16}\\ \frac{11}{48}\\ \frac{11}{48}\\ \frac{11}{48}\end{pmatrix}
$$

$$
\begin{pmatrix}\frac{11}{32}\\ \frac{7}{32}\\ \frac{7}{32}\\ \frac{7}{32}\end{pmatrix}
=
\begin{pmatrix}
0 & \frac{1}{2} & 1 & 0 \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & 0 & 0 & \frac{1}{2} \\
\frac{1}{3} & \frac{1}{2} & 0 & 0 
\end{pmatrix}
\begin{pmatrix}\frac{11}{32}\\ \frac{7}{32}\\ \frac{7}{32}\\ \frac{7}{32}\end{pmatrix}
$$

所以最终收敛到

$$
\begin{pmatrix}
A \\ B \\ C \\ D \\
\end{pmatrix}
=
\begin{pmatrix}\frac{11}{32}\\ \frac{7}{32}\\ \frac{7}{32}\\ \frac{7}{32}\end{pmatrix}
$$

## 题目四

文档D1的词频向量为 $D1 = [3,0,2,5,1]$

文档D2的词频向量为 $D2 = [1,2,0,4,3]$

余弦相似度计算文档相似性：cos(D1,D2) = $\frac{26}{3\sqrt{130}}$

欧氏距离：d(D1,D2) = $\sqrt{(3-1)^2 + (-2)^2 + 2^2 + (5-4)^2 + (1-3)^2} = \sqrt{17}$

Jaccard 相似度： JACCARD(D1,D2) = $\frac{3}{5}$

## 题目五

该用户认为前两篇文档相关,第三篇文档不相关。


$q_m = \alpha q_0 + \beta \frac{1}{|D_r|} \sum_{d \in D_r} d_j - \gamma \frac{1}{|D_{nr}|} \sum_{d \in D_{nr}} D_k$


新查询向相关文档靠拢而远离非相关文档

$q_0 = (1,1,0,0,0,0,0,0,0) ^T$

$d_1 = (1,1,1,1,0,0,0,0,0) ^T$

$d_2 = (1,1,0,0,1,1,1,0,0) ^T$

$d_3 = (0,0,0,0,1,1,0,1,1) ^T$

$|D_r| = 2,|D_nr| = 1$

最终计算得
$Q = (1.75,1.75,0.375,0.375,0.125,0.125,0.375,0,0)$


