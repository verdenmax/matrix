# 复习提纲

## 基本概念

### 搜索广告中的价格机制

搜索广告中的价格机制涉及复杂的竞价和评估系统，广告主需合理设置出价和优化广告内容，以提高广告的展示机会和点击率。理解这些机制有助于广告主在竞争激烈的市场中获得优势。

- 广告商对关键词竞标 – 拍卖方式
- 拍卖系统公开，任何人都可以参与关键词竞标
- 广告商仅在用户点击广告商才真正付费

**次高价拍卖**

次高价拍卖（Vickrey Auction）是一种特殊的拍卖形式，其主要特点是竞标者提交的出价是秘密的，且最终获胜者支付的价格是第二高的出价。

次高价拍卖是一种有效的拍卖机制，能够激励参与者真实出价，同时减少策略性出价行为。在搜索广告中，这种机制帮助广告主以相对合理的价格获得广告展示机会，同时提高了广告投放的效率。

### 停用词的影响

去除停用词可以显著减少需要索引和检索的数据量。这使得搜索引擎在处理查询时可以更快地访问和检索相关信息，从而提高总体检索速度。
停用词的去除简化了索引的结构，减少了索引表中的条目数量。这意味着在查询时，搜索引擎需要扫描的条目更少，从而加快检索过程。
去除停用词后，搜索引擎能够更好地匹配用户查询中的关键词，减少无关结果的出现。这有助于提高检索结果的相关性和准确性，从而提高正确率。
保留语义信息上下文理解：尽管停用词通常被去除，但在某些情况下，它们对上下文的理解是必要的。例如，在短语中，停用词可能帮助确定词与词之间的关系和句子的结构。
词频计算：停用词的去除可以提高有效关键词的词频计算，反映出更准确的文档相关性。去掉这些常见词后，BM25模型能够更有效地评估文档与查询的匹配程度。

使用Okapi BM25，去除停用词可以保证模型可靠性,BM25 必须去停用词

### 倒排索引

将原先的文档-> 词项，改变为 词项t -> docID。倒排索引是将文档中出现的每个词（或术语）映射到包含该词的文档列表。

why 压缩?A：占用更少的硬盘空间，将更多数据载入内存。

加快处理速度，减少从词频读入内存时间，IR中压缩基本要求为 无损压缩和随机访问。

对倒排记录表进行压缩,关键思想：存储docID 间隔而不是DocID本身

**VB 编码(可变字节码)**

应用场景：被很多商用、研究系统所采用。变长编码及对齐敏感性的简单且不错的混合产物。

设定一个专用位c（高位）作为延续位。如果间隔表示少于7bit，那么c置为1，将间隔编入一个字节后7位。

否则将高7位放入当前字节，并将c置为0，递归处理剩下的位。注意这里放入最高7位的时候需要前面补0（原先数字需要是7的倍数）

**$\gamma 编码$**

一元码：将n表示为n个1和最后一个0。如3的一元码为 `1110`

将间隔表示成长度和偏移两部分。偏移就是间隔对应的二进制编码去掉首部的1.(偏移：13 -> 1101 -> 101)

长度就是偏移的位数。（13 对应偏移为101，则长度为3），长度部分采用一元编码：1110

$\gamma$ 编码就是将长度部分和偏移部分两者联接起来得到结果。

$\gamma$ 编码是前缀无关的。编码在最优编码的2或3倍之内，不依赖于间隔的分布。

偏移部分是 $log_2 G$ 比特位，所以长度部分需要 $log_2 G + 1$ 比特位，因此全部编码需要 $2 log_2 G + 1$ 比特位。

可变字节码通常按字边界对齐，因此可能效率更高。

- 应用场景和具体实例计算,总体空间消耗评估（上面）

## 信息检索评价

### TREC 缓冲池方法

Precision/Recall 的可靠性

召回率难以计算，因为数据集比较大，需要人工得到所有的相关结果，这样才可以计算召回率。
所以使用 pooling 方法或者不考虑召回率。
pooling 技术，对多个检索系统的 top k结果组成集合进行人工标注，标注出的相关集合作为整个相关文档集合。

代表性：通过汇总多个系统的结果，缓冲池方法能够更全面地覆盖可能相关的文档，减少单一系统评估的偏差。
评估一致性：人工评估缓冲池中的文档提供了一个一致的标准，使得不同系统的评估结果可以直接比较。
减少偶然性：由于使用了多个系统的结果，缓冲池方法能够减少因某一系统的偶然性表现而导致的评估结果波动

### 评价指标

P/R/F 等基于集合的指标

- Not Retrieved 未检索出
- Retrieved 检索出
- Not Relevant 不相关
- Relevant 相关

那么召回率 Recall ： RR / (RR+NR) 返回的相关结果占总相关结果总数的比率

正确率 Precision： RR / ( RR + RN) 检索出结果中真正相关的结果

一个返回结果集是 RR + RN。 而真正的答案集是 RR + NR。

两个指标都是基于无序集合进行计算，并没有考虑排序的作用。

F值 ：召回率 R 和 正确率P的调和平均值 $F= \frac{2}{\frac{1}{P} + \frac{1}{R}} = \frac{2RP}{P + R}$

$F_{\beta}$： 其中 $\beta$ 表示召回率的重要程度是正确率的 $\beta$ 倍。 $F_{\beta} = \frac{(1 + \beta^2)PR}{P + R}$

E Effectiveness 值：召回率 R 和正确率 P 的加权平均值，b > 1则更重视P。 $E = 1-F_{\beta},b^2 = \frac{1}{\beta^2}$。这里公式: $E = 1 -  \frac{1 +b^2}{\frac{b^2}{P} + \frac{1}{R}}$ 

这里使用调和平均值是因为需要对很小的值进行做出惩罚。类似木桶效应。那么这里调和平均可以看作平滑的最小值函数。

精确率Accuracy ： $accuracy = \frac{RR+NN}{RN+RR+NR+NN}$。对于一个数据量很大，且不相关占比很多的数据，只需要一直返回NULL，就会让精确率很高。因为查询相关文档占文档的极少数。

正确率-召回率曲线：检索结果以排序的方式排列，用户不可能马上看到全部文档。在用户观察的过程中，正确率和召回率在不断变化。可以求出召回率在0，0.1，...，1下正确率，然后描出图像。

这时候又有一个问题，就是召回率有时不是一点点增加，召回率变化幅度很大，那么这时就需要插值。

P—R曲线，简单直观，即考虑了检索结果的覆盖度，又考虑了检索结果的排序情况。缺点： 难以明确表示两个查询的检索结果的优差。

Break Point ： P-R 曲线上P=R的点，这样可以进行单值比较。

AP 平均正确率：对不同召回率点上的正确率进行平均。未插值的AP，计算每个相关文档位置的精确率，若未返回文档到记为0，然后求平均（所有相关文档）。

插值的AP：在召回率0,0.1,0.2,...,1,这11个点上的正确率求平均，等价于11点平均。


**未插值 Average Precision，nDCG, bPref 等指标的设计思路和计算方法**

未插值 average Precision：
对于每个返回相关文档计算该返回位置的正确率，对于未返回位置正确率记为0。对所有已知相关文档对应的正确率求算术平均。

例子：某个查询Q共有6个相关结果，某系统排序返回了5篇相关文档，其位置分别是第1，第2，第5，第10，第20位，则AP=(1/1+2/2+3/5+4/10+5/20+0)/6

Bpref：
基本思想：在相关性判断不完全的情况下，计算在进行了相关性判断的文档集合中，在判断到相关文档前，需要判断的不相关文档的篇数。对n（标注不相关文档）排在r（标注为相关文档）前面进行惩罚。

$bpref = \frac{1}{R} \sum_r (1 - \frac{min(|n 排在r前面|,R)}{min(R,N)})$

判定结果中，R是所有相关结果，那么对于每一个相关查询，计算在它前面的不相关结果个数就是式子中上面分数。

NDCG：每个文档不仅仅有相关和不相关，而是有相关度级别。我们可以假设，对于返回结果：相关度级别越高的结果越多越好，结果越靠前越好。

计算一个结果的vector和一个最优结果的vector（使用类似前缀和方法，用对数简化），然后使用最优结果来对查询进行标准化。N(D)CG@K 表示第k个位置上的NDCG值。这个值是递减的。

图形直观，易解释。支持非二值的相关度定义，比P-R曲线更精确。能够反映用户的行为特征。

## 检索模型

了解各类检索模型的基本原理、设计思路和优缺点

### 布尔检索的查询优化

合并查询次序的策略：
查询处理中处理的顺序问题，例如合并，可以按照表从小到大的顺序进行处理。每次从最小的开始合并，这样可以尽量提前结束合并。（这里就需要每个词项term出现的doc数目，即df）

在估计OR之后的词项，可以保守通过将词项的df相加，估计OR表达式对应的倒排记录表大小。

布尔检索构建鉴定，但是查询构建复杂，不适合普通用户。构建不当，检索结果过多或过少。

### TF-IDF

tf 词项t在文档d中出现的次数。
cf 词项t的文档集频率。文档中出现的t词条的个数。
df 包含t的文档篇数。

罕见词权重更高。所以定义词项t的idf权重（逆文档频率） $idf_t = log_{10} \frac{N}{df_t}$。idf是全局性指标

tf-idf 权重是 tf权重和idf权重乘积 $w_{t,d} = (1 + log tf) log \frac{N}{df_t}$

tf-idf 权重随着词项频率的增大而增大（局部信息），随着词项罕见度的增大而增大（全局信息）

### BM25

2-Poisson 假设：二重泊松分布。在高质量精英文档集中，均值较高，接近正态分布。在整个预料中，均值低，接近指数分布。

对化简后二重泊松模型进行估计，基本原则：tf = 0 ,权重为0. 权重对tf单调递增，但增幅逐渐降低直至某最大值。

对于idf因子，假设模型中相关文档数量为0，则退化为 $w^{(1)} = log \frac{N - df + 0.5}{df + 0.5}$。df是出现词项的文档数目。

查询权重：$\frac{qtf}{k_3 + qtf}$,qtf  是词项在查询中的词频(通常是1)

权重函数：$w = \frac{qtf}{k_3 + qtf} \frac{tf}{k_1 + tf} w^{(1)}$，前面其实代表查询中词项频率，后面是文档中词项频率。

TF 因素: 对于上面单纯的 $\frac{tf}{k_1 + tf}$，加入文档长度因素 $\frac{k_1 tf}{k_1(1 - b + b \frac{l_d}{avg_l}) + tf}$。$l_d$ 是文档长度，$avg_l$ 是平均文档长度。

那么最终 $w(t,d)$ 是上面查询权重函数、TF权重、IDF 权重 的乘积。

优点：一定程度上的理论化模型。基于二重泊松假设。适用于绝大多数文本语料上IR检索应用。缺点：待调参数多且参数敏感性高，必须去停用词。

### 语言模型

SLM:即对于一个文档片段 $d=w_1w_2...w_n$，根据贝叶斯公式$p(w_1w_2...w_n) =p(w_1) \prod p(w_i | w_1 ... w_{i-1})$
这里历史 $w_1...w_{i-1}$，如果无历史，就是一元模型，最近一个历史，就是二元模型，最近N-1个历史：N元模型。

平滑处理目的：数据稀疏性导致零概率问题，如果直接计算可能会导致概率为0，但是新语料上可能出现。所以进行平滑，重新分配概率，即使没出现的事件也会赋予一个概率。

数据平滑的一般形式

$$
p(w|D)
=
\begin{cases}
P_{DML} (w|D), w \in D,(折扣后的MLE) \\
\alpha_D p(w|REF),otherwise
\end{cases}
$$

$$
\alpha_d = \frac{1 - \sum_{w\in D} P_{DML}(w |D)}{\sum_{w \notin D} p(w | REF)},
p(w|REF) = p(w|C) = \frac{\sum_D c(w,D)}{\sum_w \sum_D c(w,D)}
$$

这里的C是集合语言模型，就是w出现次数除以所有词出现的次数。

优点：理论上具有解释性，有扩展空间。有些模型虽然计算上依赖于term独立性假设，但模型本身不依赖于term独立性假设。缺点：数据稀疏性，需要参数估计。

### 网络信息采集

Web 上充斥重复内容。相对其他文档集合，Web上的重复内容更多。Web上存在大量近似重复，很难提出。可以引入边缘相关度：如果一篇高度相关文档出现在另一篇高度近似的文档后，那么该文档变得不相关。

检测语法上相似的页面。使用n-gram，然后计算Jaccard距离。Jaccard 距离对差异十分敏感。由于每篇文档Shingle个数很大，所以使用梗概sketch表示文档。

采集策略和法规遵守：  采集过程：初始化采集URL种子队列，重复如下：1.从队列去除URL，2.下载并分析网页，3.从网页抽取更多URL，4.将URL放入队列中。

规模问题：必须要分布式处理；重复网页：必须要集成重复检测功能；必须要集成作弊网页检测功能。对同一网站的访问按照协议规定。1994年起使用的采集器协议(即规定了采集器对网站的访问限制)

## Web Search

### Pagerank 和 HITS 算法

原始Pagerank公式：$R(\mu) = c \sum_{v \in B_u} \frac{R(v)}{N_v}$，R(u) 是指网页u的pagerank，B_u 是指向网页u的网页集合，N_v 是网页v出链数目。解的时候还需要使用所有点的pagerank和为1。

也可以写成矩阵的形式，进行迭代求解。第i，j填入 i -> j 的权重。然后矩阵不断乘PageRank组成的列向量。

但是原始的PageRank存在一个循环通路的话，每次迭代该循环通路中每个结点PageRank不断增加，但是不指出去。

改进后的PageRank， $R(u) = \frac{(1 - d)}{N} + d \sum_{v \in B_u} \frac{R(v)}{N_v}$。就是到达U的概率一部分是直接随机选中 (1-d)/N，另一部分是从指向它的网页而来。

### HITS (Hyperlink-induced Topic Search)

每个网页计算两个值：Hub 作为目录型网页权重。Authority作为权威型网页的权重。$A(p) = \sum H(q_i)$（其中q_i是所有链接到p的页面），$H(p)= \sum A(r_i)$ （其中r_i是所有页面p链接到的页面）。

先进行web搜索，搜索结果称为根集（结果中排名靠前的网页），将所有链向根集和根集链出的网页加入种子集合，更大的集合称为基本集。最后在基本集上计算Hub值和Authority值。

PageRank 与查询主题无关，可以实现算好，适合大型搜索引擎（是一种静态评分，需要与查询相关评分结合进行网页排序）

HITS算法计算与查询主题相关，检索后再进行计算。常用于主题相关性分析，适合社交网络分析和特定领域文献检索。

PageRank：计算复杂度较高，通常需要迭代多次，采用分布式计算可以提高效率。HITS：向对较快，计算过程中需要对链接矩阵两次迭代，一次hub，一次authority。
