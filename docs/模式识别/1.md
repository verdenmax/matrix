# 第一次作业

## 题目一

最小错误率贝叶斯决策的计算步骤

已知条件：$p(\omega_i)$ 先验概率 和 $p(x | \omega_i)$ 似然概率。

求解任务：$min\{p(error | x)\}$


先通过先验概率和似然概率计算 $p(x) = \sum_{i} p(x | \omega_i) * p(w_i)$。
然后计算出后验概率 $p(\omega_i | x) = \frac{p(x | \omega_i) * p(\omega_i)}{p(x)}$

那么 $p(error | x) = \min_{i}\{ \sum_{j}^{j \ne i} p(w_j | x)\} = min_i\{ 1 - p(\omega_i | x)\}$。

所以决策 $arg \space max_i\{p(\omega_i | x) \}$


在两类情况下最小错误率贝叶斯决策规则为

$p(\omega_1 | x) > p(\omega_2 | x), then \space x \in \omega_1,otherwise \space x \in \omega_2$。

## 题目二

最小风险贝叶斯决策


已知条件：$p(\omega_i)$ 先验概率 、 $p(x | \omega_i)$ 似然概率 、决策空间所有决策 和 损失函数 $\lambda (\alpha_i | \omega_j) $。

求解任务：观察样本x，分到那一类风险最小。

利用贝叶斯公式计算后验概率
$p(\omega_i | x) = \frac{p(x | \omega_i) * p(\omega_i)}{p(x)}$。

然后计算风险 $R(\alpha_i | x) = \sum_j \lambda(\alpha_i | \omega_j) \times p(\omega_j |x)$。

选择风险中最小的 $arg \space min_i \{ R(\alpha_i | x)\}$

两类情况下：

$R(\alpha_1 | x) = \lambda_{11} * p(\omega_1 | x) + \lambda_{12} * p(\omega_2 | x)$

$R(\alpha_2 | x) = \lambda_{21} * p(\omega_1 | x) + \lambda_{22} * p(\omega_2 | x)$

决策规则
$if R(\alpha_1 | x) < R(\alpha_2 | x) ,then \space \alpha = \alpha_1; otherwise \space \alpha = \alpha_2$

## 题目三

c类问题，各条件概率密度函数为多元正态分布

判别函数 $g_i(x) = lnp( x | \omega_i) + ln p(\omega_i) = - \frac{1}{2} (x - \mu_i)^T \sum_i^{-1} (x - \mu_i)  - \frac{d}{2}ln(2 \pi) - \frac{1}{2} ln(|\sum_i|) + ln p(\omega_i)$。

最小距离分类器：
当每一类的 $\sum_i = \sigma^2I$，并且先验概率相等( $p(\omega_i) = p(\omega_j)$ ) 时,判别函数可化简为 $g_i(x) = - \frac{1}{2 \sigma^2} ||x-\mu_i||_2^2$ ( 去掉和i无关的东西)。

线性判别函数：
当每一类的 
$\sum_i = \sigma^2I$，这时判别函数可以化简为 
$$
g_i(x) = - \frac{1}{2 \sigma^2} (x^T x - \mu_i^Tx -x^T\mu_i - \mu_i^T\mu_i) + ln p(\omega_i)  
\\
\Rightarrow 
g_i(x) = \frac{1}{\sigma^2} \mu_i^T x - \frac{1}{2 \sigma^2} \mu_i^T \mu_i + lnp(\omega_i)
$$
这时记$w_i = \frac{1}{\sigma^2} \mu_i^T$ 并且 $w_{i0} =  - \frac{1}{2 \sigma^2} \mu_i^T \mu_i + lnp(\omega_i) $，这时判别函数即为 $g_i(x) = w_i * x + w_{i0}$，是线性判别函数。

## 题目四

最大似然估计，将待估计参数视作未知但是固定的变量，最终估计出一个固定的变量。

已知条件：$p(x | \omega_i)$ 具有确定的函数形式，但是参数 $\theta$ 未知。

求解任务：构造统计量作为参数 $\theta$ 的估计 $\hat{\theta}$,此时该模型能抽取这n个样本概率最大。

先计算n个样本联合概率： 
$l(\theta) = p(D | \theta) = \prod_{i=1}^{n} p(x_i | \theta)$。

那么最大似然估计为：
$\hat{\theta} = arg \space max_\theta \{ l(\theta) \}$

如果 $l(\theta)$ 是可微的函数，那么可以使用
$\hat{\theta} = arg \space max_\theta \{ l(\theta) \} \Rightarrow \frac{\partial l(\theta)}{\partial \theta} = 0$。

## 题目五

贝叶斯估计，将待估计参数视作一个随机变量，根据观测数据对参数分布进行估计，得到参数分布概率密度。

已知条件：$p(\theta)$ 参数的先验分布、$p(x | \omega_i)$ 具有确定的函数形式$p(x | \theta)$，但是参数 $\theta$ 未知。

求解任务：估计概率密度函数 $p(x | D)$。


先根据参数先验分布和贝叶斯公式，求解参数的后验分布：
$p(\theta | D) = \frac{p(D | \theta) * P(\theta)}{p(D)}$。

使用全概率公式
$p(x | D) = \int  p(x ,\theta | D) d\theta = \int \frac{p(x,\theta ,D)}{p(D)} d\theta = \int \frac{p(x | \theta,D) * p(\theta,D)}{p(D)} d\theta = \int p(x | \theta) \times p(\theta | D) d\theta$

这样进行积分或者使用近似的方法，即可估计出概率密度函数 $p(x|D)$。


## 题目六

最大似然估计估计的只是参数空间中的一个点，贝叶斯方法则估计的是一个分布。
贝叶斯方法使用了先验概率，最大似然估计没有使用。